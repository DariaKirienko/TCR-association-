{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  current_HLA-B*35  current_other  healthy_HLA-B*35  \\\n",
      "cdr3aa                                                                \n",
      "CASSLGVGGYTF                     1              1                 1   \n",
      "CASNLQGSTEAFF                    1              1                 1   \n",
      "CASSYSYEQYF                      1              1                 1   \n",
      "CASSLGGGPYEQYF                   1              1                 1   \n",
      "CASSLGG_GNTIYF                   1              1                 1   \n",
      "...                            ...            ...               ...   \n",
      "CASSLATSGGQETQYF                 1              1                 1   \n",
      "CASSQEAGGYTF                     1              1                 1   \n",
      "CASSRGRTNTGELFF                  1              1                 1   \n",
      "CASSKQGQETQYF                    1              1                 1   \n",
      "CASSPGG_YNEQFF                   1              1                 1   \n",
      "\n",
      "                  healthy_other  \n",
      "cdr3aa                           \n",
      "CASSLGVGGYTF                  1  \n",
      "CASNLQGSTEAFF                 1  \n",
      "CASSYSYEQYF                   1  \n",
      "CASSLGGGPYEQYF                1  \n",
      "CASSLGG_GNTIYF                1  \n",
      "...                         ...  \n",
      "CASSLATSGGQETQYF              1  \n",
      "CASSQEAGGYTF                  1  \n",
      "CASSRGRTNTGELFF               1  \n",
      "CASSKQGQETQYF                 1  \n",
      "CASSPGG_YNEQFF                1  \n",
      "\n",
      "[111823 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import mymodule as md\n",
    "import os \n",
    "\n",
    "##1) импортируем датафреймы, удаляем NaN\n",
    "met_data = pd.read_csv('/projects/fmba_covid/metadata_fmba_full.txt', sep='\\t')\n",
    "met_data = met_data.dropna(subset=['sample.HLA-A.1']) \n",
    "met_data_status = pd.read_csv('/projects/fmba_covid/metadata_fmba.txt', sep='\\t')\n",
    "#удаляем subset == 'past'\n",
    "met_data_status = met_data_status.drop(met_data_status[met_data_status.subset == 'past'].index)\n",
    "public = pd.read_csv('/home/daria/TCR-association/common/pool.aa.frequent.txt', sep = '\\t')\n",
    "\n",
    "##2)находим самые частые HLA        \n",
    "def freq_value(df,start, stop, top_num):\n",
    "    result = list()\n",
    "    for item in list(df)[start: stop]:                                       \n",
    "        count = df[item].value_counts()\n",
    "        result.append(count) \n",
    "    result = pd.concat(result).sort_values(ascending=False)\n",
    "    result = result[:top_num]\n",
    "    return result\n",
    "\n",
    "##3)Создадим список частых значений hla - топ 10\n",
    "hla = freq_value(met_data, 36, 47, 10) \n",
    "hla = list(hla.index) \n",
    "##4)Объединяем ячейки HLA в одну и создаем новую ячейку\n",
    "met_data['hla'] = met_data[met_data.columns[36:47]].apply(\n",
    "    lambda x: ','.join(x.astype(str)), axis=1)\n",
    "\n",
    "##5)Создаем словари \n",
    "\n",
    "#Словарь \"название образца\" : \"список из HLA\"\n",
    "met_hla = dict(zip(list(met_data['id']), list(met_data['hla'])))\n",
    "#Словарь \"название образца\" : \"статус пациента\"  \n",
    "met_subset = dict(zip(list(met_data_status['id']), list(met_data_status['subset'])))\n",
    "\n",
    "######################\n",
    "\n",
    "#7)Создадим список cdr3aa\n",
    "cdr3_lst = list(public['cdr3aa'])        \n",
    "\n",
    "#8) Создадим пустой датафрейм\n",
    "df_col = [1]*len(cdr3_lst)\n",
    "\n",
    "df = pd.DataFrame({'current_HLA-B*35' : df_col, 'current_other' : df_col, 'healthy_HLA-B*35' : df_col, 'healthy_other' : df_col}, \n",
    "                  index = cdr3_lst)\n",
    "df.index.name='cdr3aa'\n",
    "\n",
    "#9) Меняем директорию!!!!  \n",
    "os.chdir(\"/projects/fmba_covid/hip_downsampled\")\n",
    "\n",
    "\n",
    "sample_lst = [i for i in os.listdir() if i.startswith(\"HIP\")]\n",
    "sample_lst = md.IntersLst(list(met_data['file_name']), sample_lst)\n",
    "\n",
    "#############################\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['330000380808', '590004420808', '500001990808', '500001470808', '500001920808', '670004520808', '670002260808', '330002360808', '260002940808', '330001580808', '260004150808', '250002250808', '590001270808', '690002520808', '460001030808', '330000550808', '670004700808', '330002550808', '630002590808', '260002860808', '400000290808', '630001340808', '460000160808', '540002180808', '670005360808', '260002910808', '330000660808', '360001420808', '630001450808', '730000500808', '330002370808', '670004750808', '670004790808', '540002270808', '260004180808', '400000180808', '400002860808', '250003110808', '460000180808', '330001880808', '440001580808', '670002110808', '460004470808', '730000530808', '460001300808', '670004690808', '330002530808', '690000770808', '370000580808', '630001110808', '670004980808', '670004850808', '330002060808', '330000810808', '670004510808', '580002180808', '670005070808', '330001850808', '670005680808', '590002690808', '460001130808', '500003940808', '670004810808', '360001560808', '460001480808', '630002280808', '500004180808', '500003670808', '400004360808', '670004590808', '400000130808', '590004320808', '250003530808', '290002570808', '330000610808', '540003680808', '670004530808', '330001670808', '670004910808', '540002600808', '250002490808', '670005530808', '690001180808', '520001220808', '630000880808', '330000730808', '330001860808', '330002090808', '670004670808', '260002920808', '330000600808', '730000400808', '670007900808', '330000590808', '360001410808', '340002540808', '590002150808', '520001620808', '460001010808', '670005280808', '540001040808', '500001490808', '590002880808', '670004600808', '670005150808', '500000410808', '210000150808', '730000420808', '240101580808', '670004950808', '540002970808', '500004080808', '290002620808', '670005350808', '630001430808', '330001940808', '330000500808', '330002520808', '260002950808', '590002160808', '670005540808', '590002830808', '330000740808', '360001430808', '590002560808', '540000070808', '340002530808', '670005090808', '520002170808', '590002550808', '330000520808', '330000450808', '670005460808', '460000940808', '330000800808', '520002210808', '590002680808', '460002050808', '260004200808', '540002400808', '630001250808', '670001330808', '500000230808', '590003800808', '260002880808', '440001210808', '460000280808', '670004540808', '670004940808', '500003980808', '400000110808', '330001790808', '540001360808', '460002650808', '670004890808', '500003380808', '260002850808', '330001930808', '330000700808', '670002310808', '330000560808', '460001060808', '590002210808', '670005490808', '400000310808', '460002220808', '540001930808', '590004410808', '670005000808', '670005080808', '670005400808', '330001870808', '540002140808', '540001440808', '260003000808', '300000940808', '670005640808', '590002840808', '500003930808', '460001930808', '460002230808', '460001340808', '670002450808', '500003990808', '330000750808', '670005220808', '670004960808', '260004240808', '540003420808', '250002810808', '240101640808', '540002050808', '230002190808', '500003960808', '440000470808', '670004820808', '250002880808', '670005230808', '670001240808', '240101560808', '630001530808', '670005110808', '670004580808', '460002860808', '300000710808', '460000690808', '670004800808', '360001390808', '670004620808', '670004830808', '670004550808', '540001400808', '440001090808', '550000620808', '540002780808', '630001500808', '590001290808', '500004310808', '590002090808', '500003700808', '670004880808', '730000550808', '590004310808', '590002820808', '500003440808', '630001150808', '580002170808', '670004920808', '690001770808', '330000680808', '460000890808', '670005420808', '730000410808', '500000010808', '360001830808', '330002250808', '590002490808', '590002180808', '670005320808', '330001990808', '330002540808', '630001140808', '330002580808', '250002710808', '640000670808', '670004610808', '670004770808', '500003890808', '670005370808', '590003790808', '340002960808', '260002890808', '730000540808', '540003550808', '590002670808', '300000960808', '670005710808', '330000650808', '500003040808', '540002290808', '500003850808', '440000960808', '630000860808', '670004730808', '360001680808', '370000570808', '670004680808', '140000540808', '690001970808', '730000380808', '440002980808', '330001570808', '330000860808', '330000630808', '500003920808', '540000140808', '250002660808', '520004270808', '500003530808', '440003140808', '330000540808', '500003870808', '460002740808', '330000640808', '590002140808', '670002240808', '670005050808', '370000490808', '400000210808', '140003720808', '670002290808', '670005410808', '460000880808', '540002260808', '330000390808', '360001370808', '140001090808', '670002100808', '330001730808', '670005390808', '250002590808', '140003810808', '270001190808', '360001840808', '630000750808', '260002990808', '440000330808', '670005010808', '590001280808', '670005550808', '460000170808', '690001200808', '500000220808', '640000110808', '330000430808', '250002800808', '520001830808', '410004360808', '670004780808', '540003110808', '400003590808', '400000250808', '290000390808', '340002950808', '590001680808', '580001560808', '690002180808', '440000240808', '260004160808', '460002780808', '590002120808', '670004870808', '460001050808', '520000800808', '500003950808', '670004720808', '290002630808', '500004230808', '670005650808', '260002840808', '630000290808', '670004710808', '460000990808', '460001920808', '630001510808', '670005610808', '630001440808', '500000860808', '460000440808', '250002870808', '300000920808', '670004970808', '500004190808', '330002760808', '270001050808', '330000440808', '360001400808', '520004340808', '330001280808', '260002830808', '500001040808', '540002630808', '630001240808', '140000670808', '260004220808', '580003610808', '340002510808', '670005340808', '630001930808', '590002640808', '460001100808', '630001520808', '460004460808', '260004290808', '400004310808', '360001380808', '330000510808', '460000110808', '330001710808', '520001650808', '500004290808', '250002700808', '640000850808', '330001780808', '330000130808', '360001440808', '330000620808', '500001620808', '460000920808', '460002030808', '670005130808', '670004740808', '460002020808', '670005040808', '460001280808', '540001160808', '520003590808', '250002500808', '690000780808', '670005330808', '500003560808', '590002660808', '250002690808', '730000520808']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import mymodule as md\n",
    "import os \n",
    "\n",
    "##1) импортируем датафреймы, удаляем NaN\n",
    "met_data = pd.read_csv('/projects/fmba_covid/metadata_fmba_full.txt', sep='\\t')\n",
    "met_data = met_data.dropna(subset=['sample.HLA-A.1']) \n",
    "met_data_status = pd.read_csv('/projects/fmba_covid/metadata_fmba.txt', sep='\\t')\n",
    "#удаляем subset == 'past'\n",
    "met_data_status = met_data_status.drop(met_data_status[met_data_status.subset == 'past'].index)\n",
    "public = pd.read_csv('/home/daria/TCR-association/common/pool.aa.frequent.txt', sep = '\\t')\n",
    "\n",
    "##2)находим самые частые HLA        \n",
    "def freq_value(df,start, stop, top_num):\n",
    "    result = list()\n",
    "    for item in list(df)[start: stop]:                                       \n",
    "        count = df[item].value_counts()\n",
    "        result.append(count) \n",
    "    result = pd.concat(result).sort_values(ascending=False)\n",
    "    result = result[:top_num]\n",
    "    return result\n",
    "\n",
    "##3)Создадим список частых значений hla - топ 10\n",
    "hla = freq_value(met_data, 36, 47, 10) \n",
    "hla = list(hla.index) \n",
    "##4)Объединяем ячейки HLA в одну и создаем новую ячейку\n",
    "met_data['hla'] = met_data[met_data.columns[36:47]].apply(\n",
    "    lambda x: ','.join(x.astype(str)), axis=1)\n",
    "\n",
    "##5)Создаем словари \n",
    "\n",
    "#Словарь \"название образца\" : \"список из HLA\"\n",
    "met_hla = dict(zip(list(met_data['id']), list(met_data['hla'])))\n",
    "#Словарь \"название образца\" : \"статус пациента\"  \n",
    "met_subset = dict(zip(list(met_data_status['id']), list(met_data_status['subset'])))\n",
    "\n",
    "######################\n",
    "\n",
    "#7)Создадим список cdr3aa\n",
    "cdr3_lst = list(public['cdr3aa'])        \n",
    "\n",
    "#8) Создадим пустой датафрейм\n",
    "df_col = [1]*len(cdr3_lst)\n",
    "\n",
    "df = pd.DataFrame({'current_HLA-B*35' : df_col, 'current_other' : df_col, 'healthy_HLA-B*35' : df_col, 'healthy_other' : df_col}, \n",
    "                  index = cdr3_lst)\n",
    "df.index.name='cdr3aa'\n",
    "\n",
    "#9) Меняем директорию!!!!  \n",
    "os.chdir(\"/projects/fmba_covid/data\")\n",
    "\n",
    "#10)Создаем список sample_lst - пересечение id из metadata и файлов-образцов \n",
    "sample_lst = os.listdir()\n",
    "sample_lst = list(map(lambda x: x[0 : x.find(\"_\")], sample_lst)) #отрезаем лишенее после \"_\"\n",
    "met_lst = list(map(str, list(met_data['id'])))                   #переводим элементы met_data[\"id\"] в строковый формат  \n",
    "sample_lst = md.IntersLst(met_lst, sample_lst2)                  #находим пересечение\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from mymodule.ipynb\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '330001930808'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f94852df0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssosiat_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdr3_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_hla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'current_DPB1*04:01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'current_other'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'healthy_DPB1*04:01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'healthy_other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4f94852df0e8>\u001b[0m in \u001b[0;36mAssosiat_table\u001b[0;34m(df, sample_lst, cdr3_lst, met_hla, met_cmv, hla, col1, col2, col3, col4)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m#if filename.startswith(\"HIP\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntersLst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdr3_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmet_cmv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/TCR-association/COVID-association/mymodule.ipynb\u001b[0m in \u001b[0;36mread_col\u001b[0;34m(file, n)\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '330001930808'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import mymodule as md\n",
    "import os \n",
    "\n",
    "##1) импортируем датафреймы, удаляем NaN\n",
    "met_data = pd.read_csv('/projects/fmba_covid/metadata_fmba_full.txt', sep='\\t')\n",
    "met_data = met_data.dropna(subset=['sample.HLA-A.1']) \n",
    "met_data_status = pd.read_csv('/projects/fmba_covid/metadata_fmba.txt', sep='\\t')\n",
    "#удаляем subset == 'past'\n",
    "met_data_status = met_data_status.drop(met_data_status[met_data_status.subset == 'past'].index)\n",
    "public = pd.read_csv('/home/daria/TCR-association/common/pool.aa.frequent.txt', sep = '\\t')\n",
    "\n",
    "##2)находим самые частые HLA        \n",
    "def freq_value(df,start, stop, top_num):\n",
    "    result = list()\n",
    "    for item in list(df)[start: stop]:                                       \n",
    "        count = df[item].value_counts()\n",
    "        result.append(count) \n",
    "    result = pd.concat(result).sort_values(ascending=False)\n",
    "    result = result[:top_num]\n",
    "    return result\n",
    "\n",
    "##3)Создадим список частых значений hla - топ 10\n",
    "hla = freq_value(met_data, 36, 47, 10) \n",
    "hla = list(hla.index) \n",
    "##4)Объединяем ячейки HLA в одну и создаем новую ячейку\n",
    "met_data['hla'] = met_data[met_data.columns[36:47]].apply(\n",
    "    lambda x: ','.join(x.astype(str)), axis=1)\n",
    "\n",
    "##5)Создаем словари \n",
    "\n",
    "#Словарь \"название образца\" : \"список из HLA\"\n",
    "met_hla = dict(zip(list(met_data['id']), list(met_data['hla'])))\n",
    "#Словарь \"название образца\" : \"статус пациента\"  \n",
    "met_subset = dict(zip(list(met_data_status['id']), list(met_data_status['subset'])))\n",
    "\n",
    "######################\n",
    "\n",
    "#7)Создадим список cdr3aa\n",
    "cdr3_lst = list(public['cdr3aa'])        \n",
    "\n",
    "#8) Создадим пустой датафрейм\n",
    "df_col = [1]*len(cdr3_lst)\n",
    "\n",
    "df = pd.DataFrame({'current_DPB1*04:01' : df_col, 'current_other' : df_col, 'healthy_DPB1*04:01' : df_col, 'healthy_other' : df_col}, \n",
    "                  index = cdr3_lst)\n",
    "df.index.name='cdr3aa'\n",
    "\n",
    "#9) Меняем директорию!!!!  \n",
    "os.chdir(\"/projects/fmba_covid/data\")\n",
    "\n",
    "#10)Создаем список sample_lst - пересечение id из metadata и файлов-образцов \n",
    "sample_lst = os.listdir()\n",
    "sample_lst = list(map(lambda x: x[0 : x.find(\"_\")], sample_lst)) #отрезаем лишенее после \"_\"\n",
    "met_lst = list(map(str, list(met_data['id'])))                   #переводим элементы met_data[\"id\"] в строковый формат  \n",
    "sample_lst = md.IntersLst(met_lst, sample_lst)                  #находим пересечение\n",
    "\n",
    "\n",
    "#11)Объявляем HLA\n",
    "hla = \"DPB1*04:01\" \n",
    "\n",
    "def Assosiat_table(df, sample_lst, cdr3_lst, met_hla, met_cmv, hla, col1, col2, col3, col4):\n",
    "    for filename in sample_lst:\n",
    "    #if filename.startswith(\"HIP\"):\n",
    "        sample = md.read_col(filename, 3)\n",
    "        found = md.IntersLst(cdr3_lst, sample)        \n",
    "        if met_cmv[filename]== '+':\n",
    "            if hla in list(met_hla[filename].split(',')):\n",
    "                df.loc[found, col1] += 1\n",
    "            else:\n",
    "                df.loc[found, col2] += 1\n",
    "        elif met_cmv[filename]== '-':\n",
    "            if hla in list(met_hla[filename].split(',')):\n",
    "                df.loc[found, col3] += 1\n",
    "            else: \n",
    "                df.loc[found,  col4] += 1\n",
    "    return df       \n",
    "\n",
    "\n",
    "u = Assosiat_table(df, sample_lst, cdr3_lst, met_hla, met_subset, hla, 'current_DPB1*04:01', 'current_other', 'healthy_DPB1*04:01', 'healthy_other')\n",
    "\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '330001930808'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-183856bee8df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssosiat_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcdr3_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_hla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'current_DPB1*04:01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'current_other'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'healthy_DPB1*04:01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'healthy_other'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-183856bee8df>\u001b[0m in \u001b[0;36mAssosiat_table\u001b[0;34m(df, sample_lst, cdr3_lst, met_hla, met_cmv, hla, col1, col2, col3, col4)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m#if filename.startswith(\"HIP\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntersLst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdr3_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmet_cmv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-183856bee8df>\u001b[0m in \u001b[0;36mread_col\u001b[0;34m(file, n)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '330001930808'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import mymodule as md\n",
    "import os \n",
    "\n",
    "##1) импортируем датафреймы, удаляем NaN\n",
    "met_data = pd.read_csv('/projects/fmba_covid/metadata_fmba_full.txt', sep='\\t')\n",
    "met_data = met_data.dropna(subset=['sample.HLA-A.1']) \n",
    "met_data_status = pd.read_csv('/projects/fmba_covid/metadata_fmba.txt', sep='\\t')\n",
    "#удаляем subset == 'past'\n",
    "met_data_status = met_data_status.drop(met_data_status[met_data_status.subset == 'past'].index)\n",
    "public = pd.read_csv('/home/daria/TCR-association/common/pool.aa.frequent.txt', sep = '\\t')\n",
    "\n",
    "##2)находим самые частые HLA        \n",
    "def freq_value(df,start, stop, top_num):\n",
    "    result = list()\n",
    "    for item in list(df)[start: stop]:                                       \n",
    "        count = df[item].value_counts()\n",
    "        result.append(count) \n",
    "    result = pd.concat(result).sort_values(ascending=False)\n",
    "    result = result[:top_num]\n",
    "    return result\n",
    "\n",
    "##3)Создадим список частых значений hla - топ 10\n",
    "hla = freq_value(met_data, 36, 47, 10) \n",
    "hla = list(hla.index) \n",
    "##4)Объединяем ячейки HLA в одну и создаем новую ячейку\n",
    "met_data['hla'] = met_data[met_data.columns[36:47]].apply(\n",
    "    lambda x: ','.join(x.astype(str)), axis=1)\n",
    "\n",
    "##5)Создаем словари \n",
    "\n",
    "#Словарь \"название образца\" : \"список из HLA\"\n",
    "met_hla = dict(zip(list(met_data['id']), list(met_data['hla'])))\n",
    "#Словарь \"название образца\" : \"статус пациента\"  \n",
    "met_subset = dict(zip(list(met_data_status['id']), list(met_data_status['subset'])))\n",
    "\n",
    "######################\n",
    "\n",
    "#7)Создадим список cdr3aa\n",
    "cdr3_lst = list(public['cdr3aa'])        \n",
    "\n",
    "#8) Создадим пустой датафрейм\n",
    "df_col = [1]*len(cdr3_lst)\n",
    "\n",
    "df = pd.DataFrame({'current_DPB1*04:01' : df_col, 'current_other' : df_col, 'healthy_DPB1*04:01' : df_col, 'healthy_other' : df_col}, \n",
    "                  index = cdr3_lst)\n",
    "df.index.name='cdr3aa'\n",
    "\n",
    "#9) Меняем директорию!!!!  \n",
    "os.chdir(\"/projects/fmba_covid/data\")\n",
    "\n",
    "#10)Создаем список sample_lst - пересечение id из metadata и файлов-образцов \n",
    "sample_lst = os.listdir()\n",
    "sample_lst = list(map(lambda x: x[0 : x.find(\"_\")], sample_lst)) #отрезаем лишенее после \"_\"\n",
    "met_lst = list(map(str, list(met_data['id'])))                   #переводим элементы met_data[\"id\"] в строковый формат  \n",
    "sample_lst = md.IntersLst(met_lst, sample_lst)                  #находим пересечение\n",
    "\n",
    "\n",
    "\n",
    "#1)Открывает файл, генерирует список из данных n-ого столбца    \n",
    "\n",
    "def read_col(file, n):                         \n",
    "    result = []                                     \n",
    "    with open(file) as infile:\n",
    "        for line in infile:\n",
    "            result.append((line.split()[n]))\n",
    "    return result     \n",
    "\n",
    "#2)Возвращиет пересечение двух списков\n",
    "\n",
    "def IntersLst(first, second):                     \n",
    "    in_lst =  list(set(first) & set(second))\n",
    "    return in_lst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#11)Объявляем HLA\n",
    "hla = \"DPB1*04:01\" \n",
    "\n",
    "def Assosiat_table(df, sample_lst, cdr3_lst, met_hla, met_cmv, hla, col1, col2, col3, col4):\n",
    "    for filename in sample_lst:\n",
    "    #if filename.startswith(\"HIP\"):\n",
    "        sample = read_col(filename, 3)\n",
    "        found = IntersLst(cdr3_lst, sample)        \n",
    "        if met_cmv[filename]== '+':\n",
    "            if hla in list(met_hla[filename].split(',')):\n",
    "                df.loc[found, col1] += 1\n",
    "            else:\n",
    "                df.loc[found, col2] += 1\n",
    "        elif met_cmv[filename]== '-':\n",
    "            if hla in list(met_hla[filename].split(',')):\n",
    "                df.loc[found, col3] += 1\n",
    "            else: \n",
    "                df.loc[found,  col4] += 1\n",
    "    return df       \n",
    "\n",
    "\n",
    "u = Assosiat_table(df, sample_lst, cdr3_lst, met_hla, met_subset, hla, 'current_DPB1*04:01', 'current_other', 'healthy_DPB1*04:01', 'healthy_other')\n",
    "\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "public = pd.read_csv('/projects/fmba_covid/hip_downsampled/pool/pool.aa.table.txt', sep = '\\t')\n",
    "#удаляем incidence < 20\n",
    "public = public.drop(public[public.incidence < 20].index)\n",
    "os.chdir(\"/home/daria/TCR-association/common\")\n",
    "public.to_csv('pool.aa.frequent.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-0d34668de432>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-0d34668de432>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    sample_lst = [i for i in filelst sample_lst1.append(i[0 : str.find(\"_\")])]\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import mymodule as md\n",
    "\n",
    "str = \"050000010808_S69_L001.clonotypes.TRA.pool.aa.table\"\n",
    "a = str[0 : str.find(\"_\")]\n",
    "\n",
    "\n",
    "print(a)\n",
    "\n",
    "\n",
    "\n",
    "filelst = os.listdir()\n",
    "sample_lst1 = []\n",
    "for item in \n",
    "\n",
    "sample_lst = [i for i in filelst sample_lst1.append(i[0 : str.find(\"_\")])]\n",
    "\n",
    "print(sample_lst)\n",
    "#md.DifLst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'dsdf', 'd']\n",
      "[1, 2, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "a = ['aa_a', 'dsdf_', 'd_tgjki']\n",
    "a = list(map(lambda x: x[0 : x.find(\"_\")], a))\n",
    "\n",
    "print(a)\n",
    "\n",
    "\n",
    "list_of_str = ['1', '2', '5', '10']\n",
    "\n",
    "lst = list(map(int, list_of_str))\n",
    "\n",
    "print(lst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
